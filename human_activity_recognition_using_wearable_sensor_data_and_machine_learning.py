# -*- coding: utf-8 -*-
"""Human Activity Recognition Using Wearable Sensor Data and Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_5qAwedRg8SfIq67xGGGtOGOChhs9FAL
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import statsmodels.api as sm
from sklearn.feature_selection import f_classif



# Load the training dataset
train_data = pd.read_csv('datasetkaggle1.csv')

# Display the first few rows of the dataset
print(train_data.head())

# Get the dimensions of the dataset (rows, columns)
print("Shape:", train_data.shape)

# Get statistical summary of the dataset
print(train_data.describe())

# Check for missing values
print("Missing Values:\n", train_data.isnull().sum())

# Check data types of each column
print("Data Types:\n", train_data.dtypes)

# Count the occurrences of each value in a specific column
print("Value Counts:\n", train_data['fBodyAccJerk-meanFreq()-Z'].value_counts())

# Visualize the distribution of a numeric column (histogram)
train_data['fBodyAccJerk-meanFreq()-Y'].hist()

# Visualize the relationship between two numeric columns (scatter plot)
train_data.plot.scatter(x='fBodyAccJerk-meanFreq()-Y', y='fBodyAccJerk-meanFreq()-Z')

# Visualize the relationship between a categorical column and a numeric column (box plot)
train_data.boxplot(column='fBodyAccJerk-meanFreq()-Y', by='Activity')

# Explore correlations between numeric columns (correlation matrix)
correlation_matrix = train_data.corr()
print("Correlation Matrix:\n", correlation_matrix)

# Load the preprocessed dataset
data = pd.read_csv('datasetkaggle1.csv')

print(data.columns)

# Load the dataset
data = pd.read_csv('datasetkaggle1.csv')

# Separate the features and target variable
X = data.drop(['subject', 'Activity'], axis=1)
y = data['Activity']

# Perform preprocessing steps
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

data = pd.read_csv('datasetkaggle1.csv')

# Separate the features and target variable
X = data.drop('Activity', axis=1)
y = data['Activity']

# Initialize the models
decision_tree = DecisionTreeClassifier()
random_forest = RandomForestClassifier()
svm = SVC()
knn = KNeighborsClassifier()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the models
decision_tree.fit(X_train, y_train)
random_forest.fit(X_train, y_train)
svm.fit(X_train, y_train)
knn.fit(X_train, y_train)

# Make predictions on the testing data
y_pred_dt = decision_tree.predict(X_test)
y_pred_rf = random_forest.predict(X_test)
y_pred_svm = svm.predict(X_test)
y_pred_knn = knn.predict(X_test)

# Evaluate model performance
accuracy_dt = accuracy_score(y_test, y_pred_dt)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
accuracy_svm = accuracy_score(y_test, y_pred_svm)
accuracy_knn = accuracy_score(y_test, y_pred_knn)

print("Decision Tree Accuracy:", accuracy_dt)
print("Random Forest Accuracy:", accuracy_rf)
print("SVM Accuracy:", accuracy_svm)
print("KNN Accuracy:", accuracy_knn)

# Train and evaluate the models
models = [decision_tree, random_forest, svm, knn]
model_names = ['Decision Tree', 'Random Forest', 'SVM', 'KNN']

for model, name in zip(models, model_names):
    # Train the model
    model.fit(X, y)

    # Make predictions
    y_pred = model.predict(X)

    # Calculate accuracy
    accuracy = accuracy_score(y, y_pred)
    print(f"{name} Accuracy: {accuracy}")

    # Calculate cross-validation scores
    cv_scores = cross_val_score(model, X, y, cv=5)
    print(f"{name} Cross-Validation Scores: {cv_scores}")
    print(f"{name} Mean Cross-Validation Score: {cv_scores.mean()}\n")

    # Generate classification report for model interpretation
    classification_rep = classification_report(y, y_pred)
    print(f"{name} Classification Report:\n{classification_rep}\n")

# Initialize and train the selected model
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# Save the trained model to a file
joblib.dump(model, 'trained_model.pkl')

# Calculate the z-score for each feature
z_scores = stats.zscore(X)
z_scores_df = pd.DataFrame(z_scores, columns=X.columns)
print("Z-Scores:\n", z_scores_df)

# Calculate the F-score for each feature
f_scores, p_values = f_classif(X, y)

# Create a DataFrame to store the F-scores and p-values
f_scores_df = pd.DataFrame({'Feature': X.columns, 'F-Score': f_scores, 'p-value': p_values})

# Sort the DataFrame by F-Score in descending order
f_scores_df.sort_values(by='F-Score', ascending=False, inplace=True)

# Display the F-scores and p-values
print(f_scores_df)

